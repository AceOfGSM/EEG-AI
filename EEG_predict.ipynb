{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "EEG_predict",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1nPnifi53Q26VUzOmDfIc3sTDuj2Pg_pJ",
      "authorship_tag": "ABX9TyM2JI1eamDcwriWZ9p3UKo+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ldoun/EEG-AI/blob/master/EEG_predict.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "_YbkFMhNGx0L",
        "outputId": "afb5cf68-5a7d-40ae-ba4f-341099118214"
      },
      "source": [
        "!pip install tensorflow-gpu==1.15.2\n",
        "!pip install matplotlib==1.5.3\n",
        "!pip install scikit-learn==0.19.1\n",
        "!pip install scipy==1.4.1\n",
        "!pip install numpy==1.18.2\n",
        "!pip install pandas==0.25.3\n",
        "!pip install mne==0.20.0"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow-gpu==1.15.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/32/ca/58e40e5077fa2a92004f398d705a288e958434f123938f4ce75ffe25b64b/tensorflow_gpu-1.15.2-cp36-cp36m-manylinux2010_x86_64.whl (411.0MB)\n",
            "\u001b[K     |████████████████████████████████| 411.0MB 39kB/s \n",
            "\u001b[?25hCollecting keras-applications>=1.0.8\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/71/e3/19762fdfc62877ae9102edf6342d71b28fbfd9dea3d2f96a882ce099b03f/Keras_Applications-1.0.8-py3-none-any.whl (50kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 6.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15.2) (1.33.2)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15.2) (0.2.0)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15.2) (0.8.1)\n",
            "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15.2) (0.35.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15.2) (3.3.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15.2) (1.1.2)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15.2) (1.18.5)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15.2) (1.15.0)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15.2) (0.10.0)\n",
            "Collecting gast==0.2.2\n",
            "  Downloading https://files.pythonhosted.org/packages/4e/35/11749bf99b2d4e3cceb4d55ca22590b0d7c2c62b9de38ac4a4a7f4687421/gast-0.2.2.tar.gz\n",
            "Collecting tensorflow-estimator==1.15.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/de/62/2ee9cd74c9fa2fa450877847ba560b260f5d0fb70ee0595203082dafcc9d/tensorflow_estimator-1.15.1-py2.py3-none-any.whl (503kB)\n",
            "\u001b[K     |████████████████████████████████| 512kB 44.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15.2) (1.1.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15.2) (1.12.1)\n",
            "Collecting tensorboard<1.16.0,>=1.15.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1e/e9/d3d747a97f7188f48aa5eda486907f3b345cd409f0a0850468ba867db246/tensorboard-1.15.0-py3-none-any.whl (3.8MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8MB 44.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15.2) (3.12.4)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.8->tensorflow-gpu==1.15.2) (2.10.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow-gpu==1.15.2) (50.3.2)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow-gpu==1.15.2) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow-gpu==1.15.2) (3.3.3)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow-gpu==1.15.2) (2.0.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow-gpu==1.15.2) (3.4.0)\n",
            "Building wheels for collected packages: gast\n",
            "  Building wheel for gast (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gast: filename=gast-0.2.2-cp36-none-any.whl size=7542 sha256=63a1090299343fe83eb532c1dabefea8e465d04f8d4076f2b3f5b87435e9a749\n",
            "  Stored in directory: /root/.cache/pip/wheels/5c/2e/7e/a1d4d4fcebe6c381f378ce7743a3ced3699feb89bcfbdadadd\n",
            "Successfully built gast\n",
            "\u001b[31mERROR: tensorflow 2.3.0 has requirement gast==0.3.3, but you'll have gast 0.2.2 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: tensorflow 2.3.0 has requirement tensorboard<3,>=2.3.0, but you'll have tensorboard 1.15.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: tensorflow 2.3.0 has requirement tensorflow-estimator<2.4.0,>=2.3.0, but you'll have tensorflow-estimator 1.15.1 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: tensorflow-probability 0.11.0 has requirement gast>=0.3.2, but you'll have gast 0.2.2 which is incompatible.\u001b[0m\n",
            "Installing collected packages: keras-applications, gast, tensorflow-estimator, tensorboard, tensorflow-gpu\n",
            "  Found existing installation: gast 0.3.3\n",
            "    Uninstalling gast-0.3.3:\n",
            "      Successfully uninstalled gast-0.3.3\n",
            "  Found existing installation: tensorflow-estimator 2.3.0\n",
            "    Uninstalling tensorflow-estimator-2.3.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.3.0\n",
            "  Found existing installation: tensorboard 2.3.0\n",
            "    Uninstalling tensorboard-2.3.0:\n",
            "      Successfully uninstalled tensorboard-2.3.0\n",
            "Successfully installed gast-0.2.2 keras-applications-1.0.8 tensorboard-1.15.0 tensorflow-estimator-1.15.1 tensorflow-gpu-1.15.2\n",
            "Collecting matplotlib==1.5.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/61/f6/9aeee05e614043add127f1485a8e25758bed58f2a5361bbd870aa071e87a/matplotlib-1.5.3-cp36-cp36m-manylinux1_x86_64.whl (13.7MB)\n",
            "\u001b[K     |████████████████████████████████| 13.8MB 342kB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.6/dist-packages (from matplotlib==1.5.3) (1.18.5)\n",
            "Requirement already satisfied: pyparsing!=2.0.0,!=2.0.4,!=2.1.2,>=1.5.6 in /usr/local/lib/python3.6/dist-packages (from matplotlib==1.5.3) (2.4.7)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.6/dist-packages (from matplotlib==1.5.3) (2018.9)\n",
            "Requirement already satisfied: cycler in /usr/local/lib/python3.6/dist-packages (from matplotlib==1.5.3) (0.10.0)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.6/dist-packages (from matplotlib==1.5.3) (2.8.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from cycler->matplotlib==1.5.3) (1.15.0)\n",
            "\u001b[31mERROR: seaborn 0.11.0 has requirement matplotlib>=2.2, but you'll have matplotlib 1.5.3 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: scikit-image 0.16.2 has requirement matplotlib!=3.0.0,>=2.0.0, but you'll have matplotlib 1.5.3 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: pycocotools 2.0.2 has requirement matplotlib>=2.1.0, but you'll have matplotlib 1.5.3 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: plotnine 0.6.0 has requirement matplotlib>=3.1.1, but you'll have matplotlib 1.5.3 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: mizani 0.6.0 has requirement matplotlib>=3.1.1, but you'll have matplotlib 1.5.3 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: fbprophet 0.7.1 has requirement matplotlib>=2.0.0, but you'll have matplotlib 1.5.3 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Installing collected packages: matplotlib\n",
            "  Found existing installation: matplotlib 3.2.2\n",
            "    Uninstalling matplotlib-3.2.2:\n",
            "      Successfully uninstalled matplotlib-3.2.2\n",
            "Successfully installed matplotlib-1.5.3\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "matplotlib",
                  "mpl_toolkits"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Collecting scikit-learn==0.19.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3d/2d/9fbc7baa5f44bc9e88ffb7ed32721b879bfa416573e85031e16f52569bc9/scikit_learn-0.19.1-cp36-cp36m-manylinux1_x86_64.whl (12.4MB)\n",
            "\u001b[K     |████████████████████████████████| 12.4MB 8.6MB/s \n",
            "\u001b[31mERROR: yellowbrick 0.9.1 has requirement scikit-learn>=0.20, but you'll have scikit-learn 0.19.1 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: umap-learn 0.4.6 has requirement scikit-learn>=0.20, but you'll have scikit-learn 0.19.1 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: imbalanced-learn 0.4.3 has requirement scikit-learn>=0.20, but you'll have scikit-learn 0.19.1 which is incompatible.\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: scikit-learn\n",
            "  Found existing installation: scikit-learn 0.22.2.post1\n",
            "    Uninstalling scikit-learn-0.22.2.post1:\n",
            "      Successfully uninstalled scikit-learn-0.22.2.post1\n",
            "Successfully installed scikit-learn-0.19.1\n",
            "Requirement already satisfied: scipy==1.4.1 in /usr/local/lib/python3.6/dist-packages (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from scipy==1.4.1) (1.18.5)\n",
            "Collecting numpy==1.18.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/07/08/a549ba8b061005bb629b76adc000f3caaaf881028b963c2e18f811c6edc1/numpy-1.18.2-cp36-cp36m-manylinux1_x86_64.whl (20.2MB)\n",
            "\u001b[K     |████████████████████████████████| 20.2MB 49.7MB/s \n",
            "\u001b[31mERROR: yellowbrick 0.9.1 has requirement scikit-learn>=0.20, but you'll have scikit-learn 0.19.1 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: umap-learn 0.4.6 has requirement scikit-learn>=0.20, but you'll have scikit-learn 0.19.1 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: tensorflow 2.3.0 has requirement gast==0.3.3, but you'll have gast 0.2.2 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: tensorflow 2.3.0 has requirement tensorboard<3,>=2.3.0, but you'll have tensorboard 1.15.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: tensorflow 2.3.0 has requirement tensorflow-estimator<2.4.0,>=2.3.0, but you'll have tensorflow-estimator 1.15.1 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: tensorflow-probability 0.11.0 has requirement gast>=0.3.2, but you'll have gast 0.2.2 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: seaborn 0.11.0 has requirement matplotlib>=2.2, but you'll have matplotlib 1.5.3 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: scikit-image 0.16.2 has requirement matplotlib!=3.0.0,>=2.0.0, but you'll have matplotlib 1.5.3 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: plotnine 0.6.0 has requirement matplotlib>=3.1.1, but you'll have matplotlib 1.5.3 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: mizani 0.6.0 has requirement matplotlib>=3.1.1, but you'll have matplotlib 1.5.3 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: imbalanced-learn 0.4.3 has requirement scikit-learn>=0.20, but you'll have scikit-learn 0.19.1 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: fbprophet 0.7.1 has requirement matplotlib>=2.0.0, but you'll have matplotlib 1.5.3 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: numpy\n",
            "  Found existing installation: numpy 1.18.5\n",
            "    Uninstalling numpy-1.18.5:\n",
            "      Successfully uninstalled numpy-1.18.5\n",
            "Successfully installed numpy-1.18.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Collecting pandas==0.25.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/52/3f/f6a428599e0d4497e1595030965b5ba455fd8ade6e977e3c819973c4b41d/pandas-0.25.3-cp36-cp36m-manylinux1_x86_64.whl (10.4MB)\n",
            "\u001b[K     |████████████████████████████████| 10.4MB 8.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas==0.25.3) (2.8.1)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from pandas==0.25.3) (1.18.2)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas==0.25.3) (2018.9)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.6.1->pandas==0.25.3) (1.15.0)\n",
            "\u001b[31mERROR: seaborn 0.11.0 has requirement matplotlib>=2.2, but you'll have matplotlib 1.5.3 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: plotnine 0.6.0 has requirement matplotlib>=3.1.1, but you'll have matplotlib 1.5.3 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: mizani 0.6.0 has requirement matplotlib>=3.1.1, but you'll have matplotlib 1.5.3 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: google-colab 1.0.0 has requirement pandas~=1.1.0; python_version >= \"3.0\", but you'll have pandas 0.25.3 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: fbprophet 0.7.1 has requirement matplotlib>=2.0.0, but you'll have matplotlib 1.5.3 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: fbprophet 0.7.1 has requirement pandas>=1.0.4, but you'll have pandas 0.25.3 which is incompatible.\u001b[0m\n",
            "Installing collected packages: pandas\n",
            "  Found existing installation: pandas 1.1.4\n",
            "    Uninstalling pandas-1.1.4:\n",
            "      Successfully uninstalled pandas-1.1.4\n",
            "Successfully installed pandas-0.25.3\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "pandas"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Collecting mne==0.20.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/01/af/9c64ac8f75b1c932ca5fb16bc27740cd9b9817f9173a6608ae999e82bb6a/mne-0.20.0-py3-none-any.whl (6.5MB)\n",
            "\u001b[K     |████████████████████████████████| 6.6MB 5.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy>=0.17.1 in /usr/local/lib/python3.6/dist-packages (from mne==0.20.0) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.6/dist-packages (from mne==0.20.0) (1.18.2)\n",
            "Installing collected packages: mne\n",
            "Successfully installed mne-0.20.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wZSuyVJrdGUi"
      },
      "source": [
        "import tensorflow as tf\n",
        "import sys\n",
        "import os\n",
        "sys.path.append('/content/drive/MyDrive/EEG_classification/EEG')\n",
        "from deepsleep.model import DeepSleepNet\n",
        "from deepsleep.sleep_stage import (NUM_CLASSES,\n",
        "                                   EPOCH_SEC_LEN,\n",
        "                                   SAMPLING_RATE)\n",
        "from deepsleep.nn import *\n",
        "from tensorflow.python.util import nest\n",
        "from tensorflow.python.framework import tensor_shape\n",
        "from tensorflow.python.ops import array_ops\n",
        "from tensorflow.python.ops import math_ops\n",
        "from tensorflow.python.ops import variable_scope as vs\n",
        "from datetime import datetime\n",
        "import time\n",
        "from deepsleep.utils import iterate_batch_seq_minibatches\n",
        "#from deepsleep.data_loader import SeqDataLoader"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "7SnMCx1-jG5J",
        "outputId": "e240ecb6-e440-4361-e4aa-3991168a9e48"
      },
      "source": [
        "'''with tf.compat.v1.Session() as sess:\n",
        "  saver = tf.compat.v1.train.Saver(tf.compat.v1.global_variables(), max_to_keep=0)\n",
        "  sess.run(tf.compat.v1.global_variables_initializer())\n",
        "  output_dir = '/content/drive/MyDrive/EEG_classification/EEG/output/fold17/deepsleepnet' \n",
        "  saver.restore(sess, tf.train.latest_checkpoint(output_dir))'''"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"with tf.compat.v1.Session() as sess:\\n  saver = tf.compat.v1.train.Saver(tf.compat.v1.global_variables(), max_to_keep=0)\\n  sess.run(tf.compat.v1.global_variables_initializer())\\n  output_dir = '/content/drive/MyDrive/EEG_classification/EEG/output/fold17/deepsleepnet' \\n  saver.restore(sess, tf.train.latest_checkpoint(output_dir))\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mvdwBO98nrfe"
      },
      "source": [
        "def custom_rnn(cell, inputs, initial_state=None, dtype=None,\n",
        "        sequence_length=None, scope=None):\n",
        "    \"\"\"Creates a recurrent neural network specified by RNNCell `cell`.\n",
        "    The simplest form of RNN network generated is:\n",
        "    ```python\n",
        "        state = cell.zero_state(...)\n",
        "        outputs = []\n",
        "        for input_ in inputs:\n",
        "            output, state = cell(input_, state)\n",
        "            outputs.append(output)\n",
        "        return (outputs, state)\n",
        "    ```\n",
        "    However, a few other options are available:\n",
        "    An initial state can be provided.\n",
        "    If the sequence_length vector is provided, dynamic calculation is performed.\n",
        "    This method of calculation does not compute the RNN steps past the maximum\n",
        "    sequence length of the minibatch (thus saving computational time),\n",
        "    and properly propagates the state at an example's sequence length\n",
        "    to the final state output.\n",
        "    The dynamic calculation performed is, at time `t` for batch row `b`,\n",
        "    ```python\n",
        "        (output, state)(b, t) =\n",
        "            (t >= sequence_length(b))\n",
        "                ? (zeros(cell.output_size), states(b, sequence_length(b) - 1))\n",
        "                : cell(input(b, t), state(b, t - 1))\n",
        "    ```\n",
        "    Args:\n",
        "        cell: An instance of RNNCell.\n",
        "        inputs: A length T list of inputs, each a `Tensor` of shape\n",
        "            `[batch_size, input_size]`, or a nested tuple of such elements.\n",
        "        initial_state: (optional) An initial state for the RNN.\n",
        "            If `cell.state_size` is an integer, this must be\n",
        "            a `Tensor` of appropriate type and shape `[batch_size, cell.state_size]`.\n",
        "            If `cell.state_size` is a tuple, this should be a tuple of\n",
        "            tensors having shapes `[batch_size, s] for s in cell.state_size`.\n",
        "        dtype: (optional) The data type for the initial state and expected output.\n",
        "            Required if initial_state is not provided or RNN state has a heterogeneous\n",
        "            dtype.\n",
        "        sequence_length: Specifies the length of each sequence in inputs.\n",
        "            An int32 or int64 vector (tensor) size `[batch_size]`, values in `[0, T)`.\n",
        "        scope: VariableScope for the created subgraph; defaults to \"RNN\".\n",
        "    Returns:\n",
        "        A pair (outputs, state) where:\n",
        "        - outputs is a length T list of outputs (one for each input), or a nested\n",
        "            tuple of such elements.\n",
        "        - state is the final state\n",
        "    Raises:\n",
        "        TypeError: If `cell` is not an instance of RNNCell.\n",
        "        ValueError: If `inputs` is `None` or an empty list, or if the input depth\n",
        "            (column size) cannot be inferred from inputs via shape inference.\n",
        "    \"\"\"\n",
        "\n",
        "    if not isinstance(cell, tf.compat.v1.nn.rnn_cell.RNNCell):\n",
        "        raise TypeError(\"cell must be an instance of RNNCell\")\n",
        "    if not nest.is_sequence(inputs):\n",
        "        raise TypeError(\"inputs must be a sequence\")\n",
        "    if not inputs:\n",
        "        raise ValueError(\"inputs must not be empty\")\n",
        "\n",
        "    outputs = []\n",
        "    states = []\n",
        "    # Create a new scope in which the caching device is either\n",
        "    # determined by the parent scope, or is set to place the cached\n",
        "    # Variable using the same placement as for the rest of the RNN.\n",
        "    with vs.variable_scope(scope or \"RNN\") as varscope:\n",
        "        if varscope.caching_device is None:\n",
        "            varscope.set_caching_device(lambda op: op.device)\n",
        "\n",
        "        # Obtain the first sequence of the input\n",
        "        first_input = inputs\n",
        "        while nest.is_sequence(first_input):\n",
        "            first_input = first_input[0]\n",
        "\n",
        "        # Temporarily avoid EmbeddingWrapper and seq2seq badness\n",
        "        # TODO(lukaszkaiser): remove EmbeddingWrapper\n",
        "        if first_input.get_shape().ndims != 1:\n",
        "\n",
        "            input_shape = first_input.get_shape().with_rank_at_least(2)\n",
        "            fixed_batch_size = input_shape[0]\n",
        "\n",
        "            flat_inputs = nest.flatten(inputs)\n",
        "            for flat_input in flat_inputs:\n",
        "                input_shape = flat_input.get_shape().with_rank_at_least(2)\n",
        "                batch_size, input_size = input_shape[0], input_shape[1:]\n",
        "                fixed_batch_size.merge_with(batch_size)\n",
        "                for i, size in enumerate(input_size):\n",
        "                    if size.value is None:\n",
        "                        raise ValueError(\n",
        "                            \"Input size (dimension %d of inputs) must be accessible via \"\n",
        "                            \"shape inference, but saw value None.\" % i)\n",
        "        else:\n",
        "            fixed_batch_size = first_input.get_shape().with_rank_at_least(1)[0]\n",
        "\n",
        "        if fixed_batch_size.value:\n",
        "            batch_size = fixed_batch_size.value\n",
        "        else:\n",
        "            batch_size = array_ops.shape(first_input)[0]\n",
        "        if initial_state is not None:\n",
        "            state = initial_state\n",
        "        else:\n",
        "            if not dtype:\n",
        "                raise ValueError(\"If no initial_state is provided, \"\n",
        "                                 \"dtype must be specified\")\n",
        "            state = cell.zero_state(batch_size, dtype)\n",
        "\n",
        "        if sequence_length is not None:  # Prepare variables\n",
        "            sequence_length = ops.convert_to_tensor(\n",
        "                sequence_length, name=\"sequence_length\")\n",
        "            if sequence_length.get_shape().ndims not in (None, 1):\n",
        "                raise ValueError(\n",
        "                    \"sequence_length must be a vector of length batch_size\")\n",
        "            def _create_zero_output(output_size):\n",
        "                # convert int to TensorShape if necessary\n",
        "                size = _state_size_with_prefix(output_size, prefix=[batch_size])\n",
        "                output = array_ops.zeros(\n",
        "                    array_ops.pack(size), _infer_state_dtype(dtype, state))\n",
        "                shape = _state_size_with_prefix(\n",
        "                    output_size, prefix=[fixed_batch_size.value])\n",
        "                output.set_shape(tensor_shape.TensorShape(shape))\n",
        "                return output\n",
        "\n",
        "            output_size = cell.output_size\n",
        "            flat_output_size = nest.flatten(output_size)\n",
        "            flat_zero_output = tuple(\n",
        "                _create_zero_output(size) for size in flat_output_size)\n",
        "            zero_output = nest.pack_sequence_as(structure=output_size,\n",
        "                                                flat_sequence=flat_zero_output)\n",
        "\n",
        "            sequence_length = math_ops.to_int32(sequence_length)\n",
        "            min_sequence_length = math_ops.reduce_min(sequence_length)\n",
        "            max_sequence_length = math_ops.reduce_max(sequence_length)\n",
        "\n",
        "        for time, input_ in enumerate(inputs):\n",
        "            if time > 0: varscope.reuse_variables()\n",
        "            # pylint: disable=cell-var-from-loop\n",
        "            call_cell = lambda: cell(input_, state)\n",
        "            # pylint: enable=cell-var-from-loop\n",
        "            if sequence_length is not None:\n",
        "                (output, state) = _rnn_step(\n",
        "                    time=time,\n",
        "                    sequence_length=sequence_length,\n",
        "                    min_sequence_length=min_sequence_length,\n",
        "                    max_sequence_length=max_sequence_length,\n",
        "                    zero_output=zero_output,\n",
        "                    state=state,\n",
        "                    call_cell=call_cell,\n",
        "                    state_size=cell.state_size)\n",
        "            else:\n",
        "                (output, state) = call_cell()\n",
        "\n",
        "            outputs.append(output)\n",
        "            states.append(state)\n",
        "\n",
        "        return (outputs, state, states)\n",
        "\n",
        "    \n",
        "def custom_bidirectional_rnn(cell_fw, cell_bw, inputs,\n",
        "                             initial_state_fw=None, initial_state_bw=None,\n",
        "                             dtype=None, sequence_length=None, scope=None):\n",
        "    \"\"\"Creates a bidirectional recurrent neural network.\n",
        "    Similar to the unidirectional case above (rnn) but takes input and builds\n",
        "    independent forward and backward RNNs with the final forward and backward\n",
        "    outputs depth-concatenated, such that the output will have the format\n",
        "    [time][batch][cell_fw.output_size + cell_bw.output_size]. The input_size of\n",
        "    forward and backward cell must match. The initial state for both directions\n",
        "    is zero by default (but can be set optionally) and no intermediate states are\n",
        "    ever returned -- the network is fully unrolled for the given (passed in)\n",
        "    length(s) of the sequence(s) or completely unrolled if length(s) is not given.\n",
        "    Args:\n",
        "        cell_fw: An instance of RNNCell, to be used for forward direction.\n",
        "        cell_bw: An instance of RNNCell, to be used for backward direction.\n",
        "        inputs: A length T list of inputs, each a tensor of shape\n",
        "            [batch_size, input_size], or a nested tuple of such elements.\n",
        "        initial_state_fw: (optional) An initial state for the forward RNN.\n",
        "            This must be a tensor of appropriate type and shape\n",
        "            `[batch_size, cell_fw.state_size]`.\n",
        "            If `cell_fw.state_size` is a tuple, this should be a tuple of\n",
        "            tensors having shapes `[batch_size, s] for s in cell_fw.state_size`.\n",
        "        initial_state_bw: (optional) Same as for `initial_state_fw`, but using\n",
        "            the corresponding properties of `cell_bw`.\n",
        "        dtype: (optional) The data type for the initial state.  Required if\n",
        "            either of the initial states are not provided.\n",
        "        sequence_length: (optional) An int32/int64 vector, size `[batch_size]`,\n",
        "            containing the actual lengths for each of the sequences.\n",
        "        scope: VariableScope for the created subgraph; defaults to \"BiRNN\"\n",
        "    Returns:\n",
        "        A tuple (outputs, output_state_fw, output_state_bw) where:\n",
        "            outputs is a length `T` list of outputs (one for each input), which\n",
        "                are depth-concatenated forward and backward outputs.\n",
        "            output_state_fw is the final state of the forward rnn.\n",
        "            output_state_bw is the final state of the backward rnn.\n",
        "    Raises:\n",
        "        TypeError: If `cell_fw` or `cell_bw` is not an instance of `RNNCell`.\n",
        "        ValueError: If inputs is None or an empty list.\n",
        "    \"\"\"\n",
        "\n",
        "    if not isinstance(cell_fw, tf.compat.v1.nn.rnn_cell.RNNCell):\n",
        "        raise TypeError(\"cell_fw must be an instance of RNNCell\")\n",
        "    if not isinstance(cell_bw, tf.compat.v1.nn.rnn_cell.RNNCell):\n",
        "        raise TypeError(\"cell_bw must be an instance of RNNCell\")\n",
        "    if not nest.is_sequence(inputs):\n",
        "        raise TypeError(\"inputs must be a sequence\")\n",
        "    if not inputs:\n",
        "        raise ValueError(\"inputs must not be empty\")\n",
        "\n",
        "    with vs.variable_scope(scope or \"bidirectional_rnn\"):\n",
        "        # Forward direction\n",
        "        with vs.variable_scope(\"fw\") as fw_scope:\n",
        "            output_fw, output_state_fw, fw_states = custom_rnn(\n",
        "                cell_fw, inputs, initial_state_fw, dtype,\n",
        "                sequence_length, scope=fw_scope\n",
        "            )\n",
        "\n",
        "        # Backward direction\n",
        "        with vs.variable_scope(\"bw\") as bw_scope:\n",
        "            reversed_inputs = _reverse_seq(inputs, sequence_length)\n",
        "            tmp, output_state_bw, tmp_states = custom_rnn(\n",
        "                cell_bw, reversed_inputs, initial_state_bw,\n",
        "                dtype, sequence_length, scope=bw_scope\n",
        "            )\n",
        "\n",
        "    output_bw = _reverse_seq(tmp, sequence_length)\n",
        "    bw_states = _reverse_seq(tmp_states, sequence_length)\n",
        "\n",
        "    # Concat each of the forward/backward outputs\n",
        "    flat_output_fw = nest.flatten(output_fw)\n",
        "    flat_output_bw = nest.flatten(output_bw)\n",
        "\n",
        "    flat_outputs = tuple(array_ops.concat(values=[fw, bw], axis=1)\n",
        "                        for fw, bw in zip(flat_output_fw, flat_output_bw))\n",
        "\n",
        "    outputs = nest.pack_sequence_as(structure=output_fw,\n",
        "                                    flat_sequence=flat_outputs)\n",
        "\n",
        "    return (outputs, output_state_fw, output_state_bw, fw_states, bw_states)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        },
        "id": "v8B0M8Kk1GuD",
        "outputId": "8854970c-604d-41a3-bb84-49ce12d3b3d9"
      },
      "source": [
        "def custom_run_epoch(\n",
        "    sess, \n",
        "    network, \n",
        "    inputs,  \n",
        "    train_op, \n",
        "    is_train, \n",
        "    output_dir, \n",
        "    subject_idx\n",
        "):\n",
        "    start_time = time.time()\n",
        "    y = []\n",
        "    all_fw_memory_cells = []\n",
        "    all_bw_memory_cells = []\n",
        "    total_loss, n_batches = 0.0, 0\n",
        "    for each_data in enumerate(inputs):\n",
        "        each_x= each_data #each_y 제거\n",
        "\n",
        "        # # Initialize state of LSTM - Unidirectional LSTM\n",
        "        # state = sess.run(network.initial_state)\n",
        "\n",
        "        # Initialize state of LSTM - Bidirectional LSTM\n",
        "        fw_state = sess.run(network.fw_initial_state)\n",
        "        bw_state = sess.run(network.bw_initial_state)\n",
        "\n",
        "        # Prepare storage for memory cells\n",
        "        n_all_data = len(each_x)\n",
        "        extra = n_all_data % network.seq_length\n",
        "        n_data = n_all_data - extra\n",
        "        cell_size = 512\n",
        "        fw_memory_cells = np.zeros((n_data, network.n_rnn_layers, cell_size))\n",
        "        bw_memory_cells = np.zeros((n_data, network.n_rnn_layers, cell_size))\n",
        "        seq_idx = 0\n",
        "\n",
        "        # Store prediction and actual stages of each patient\n",
        "        each_y_pred = []\n",
        "\n",
        "        for x_batch in iterate_batch_seq_minibatches(inputs=each_x,\n",
        "                                                            batch_size=network.batch_size,\n",
        "                                                              seq_length=network.seq_length):\n",
        "            feed_dict = {\n",
        "                network.input_var: x_batch\n",
        "            }\n",
        "\n",
        "            # Unidirectional LSTM\n",
        "            # for i, (c, h) in enumerate(network.initial_state):\n",
        "            #     feed_dict[c] = state[i].c\n",
        "            #     feed_dict[h] = state[i].h\n",
        "\n",
        "            # _, loss_value, y_pred, state = sess.run(\n",
        "            #     [train_op, network.loss_op, network.pred_op, network.final_state],\n",
        "            #     feed_dict=feed_dict\n",
        "            # )\n",
        "\n",
        "            for i, (c, h) in enumerate(network.fw_initial_state):\n",
        "                feed_dict[c] = fw_state[i].c\n",
        "                feed_dict[h] = fw_state[i].h\n",
        "\n",
        "            for i, (c, h) in enumerate(network.bw_initial_state):\n",
        "                feed_dict[c] = bw_state[i].c\n",
        "                feed_dict[h] = bw_state[i].h\n",
        "\n",
        "            _, loss_value, y_pred, fw_state, bw_state = sess.run(\n",
        "                [train_op, network.loss_op, network.pred_op, network.fw_final_state, network.bw_final_state],\n",
        "                feed_dict=feed_dict\n",
        "            )\n",
        "\n",
        "            # Extract memory cells\n",
        "            fw_states = sess.run(network.fw_states, feed_dict=feed_dict)\n",
        "            bw_states = sess.run(network.bw_states, feed_dict=feed_dict)\n",
        "            offset_idx = seq_idx * network.seq_length\n",
        "            for s_idx in range(network.seq_length):\n",
        "                for r_idx in range(network.n_rnn_layers):\n",
        "                    fw_memory_cells[offset_idx + s_idx][r_idx] = np.squeeze(fw_states[s_idx][r_idx].c)\n",
        "                    bw_memory_cells[offset_idx + s_idx][r_idx] = np.squeeze(bw_states[s_idx][r_idx].c)\n",
        "            seq_idx += 1\n",
        "            each_y_pred.extend(y_pred)\n",
        "\n",
        "            total_loss += loss_value\n",
        "            n_batches += 1\n",
        "\n",
        "            # Check the loss value\n",
        "            assert not np.isnan(loss_value), \\\n",
        "                \"Model diverged with loss = NaN\"\n",
        "\n",
        "        all_fw_memory_cells.append(fw_memory_cells)\n",
        "        all_bw_memory_cells.append(bw_memory_cells)\n",
        "        y.append(each_y_pred)\n",
        "\n",
        "    # Save memory cells and predictions\n",
        "    save_dict = {\n",
        "        \"fw_memory_cells\": fw_memory_cells,\n",
        "        \"bw_memory_cells\": bw_memory_cells,\n",
        "        \"y_pred\": y\n",
        "    }\n",
        "    save_path = os.path.join(\n",
        "        output_dir,\n",
        "        \"output_subject{}.npz\".format(subject_idx)\n",
        "    )\n",
        "\n",
        "    duration = time.time() - start_time\n",
        "    total_loss /= n_batches\n",
        "    total_y_pred = np.hstack(y)\n",
        "    total_y_true = np.hstack(y_true)\n",
        "\n",
        "    return total_y_pred, total_loss, duration"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-12-4148a36d9a3d>\"\u001b[0;36m, line \u001b[0;32m75\u001b[0m\n\u001b[0;31m    seq_idx += 1            each_y_pred.extend(y_pred)\u001b[0m\n\u001b[0m                                      ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K4gZ9bPijxzB"
      },
      "source": [
        "class CustomDeepSleepNet(DeepSleepNet):\n",
        "    def __init__(\n",
        "        self, \n",
        "        batch_size, \n",
        "        input_dims, \n",
        "        n_classes, \n",
        "        seq_length,\n",
        "        n_rnn_layers,\n",
        "        return_last,\n",
        "        is_train, \n",
        "        reuse_params,\n",
        "        use_dropout_feature, \n",
        "        use_dropout_sequence,\n",
        "        name=\"deepsleepnet\"\n",
        "    ):\n",
        "        super(DeepSleepNet, self).__init__(\n",
        "            batch_size=batch_size, \n",
        "            input_dims=input_dims, \n",
        "            n_classes=n_classes, \n",
        "            is_train=is_train, \n",
        "            reuse_params=reuse_params, \n",
        "            use_dropout=use_dropout_feature, \n",
        "            name=name\n",
        "        )\n",
        "\n",
        "        self.seq_length = seq_length\n",
        "        self.n_rnn_layers = n_rnn_layers\n",
        "        self.return_last = return_last\n",
        "\n",
        "        self.use_dropout_sequence = use_dropout_sequence\n",
        "\n",
        "    def build_model(self, input_var):\n",
        "        # Create a network with superclass method\n",
        "        network = super(DeepSleepNet, self).build_model(\n",
        "            input_var=self.input_var\n",
        "        )\n",
        "\n",
        "        # Residual (or shortcut) connection\n",
        "        output_conns = []\n",
        "\n",
        "        # Fully-connected to select some part of the output to add with the output from bi-directional LSTM\n",
        "        name = \"l{}_fc\".format(self.layer_idx)\n",
        "        with tf.compat.v1.variable_scope(name) as scope:\n",
        "            output_tmp = fc(name=\"fc\", input_var=network, n_hiddens=1024, bias=None, wd=0)\n",
        "            output_tmp = batch_norm_new(name=\"bn\", input_var=output_tmp, is_train=self.is_train)\n",
        "            output_tmp = tf.nn.relu(output_tmp, name=\"relu\")\n",
        "        self.activations.append((name, output_tmp))\n",
        "        self.layer_idx += 1\n",
        "        output_conns.append(output_tmp)\n",
        "\n",
        "        ######################################################################\n",
        "\n",
        "        # Reshape the input from (batch_size * seq_length, input_dim) to\n",
        "        # (batch_size, seq_length, input_dim)\n",
        "        name = \"l{}_reshape_seq\".format(self.layer_idx)\n",
        "        input_dim = network.get_shape()[-1].value\n",
        "        seq_input = tf.reshape(network,\n",
        "                               shape=[-1, self.seq_length, input_dim],\n",
        "                               name=name)\n",
        "        assert self.batch_size == seq_input.get_shape()[0].value\n",
        "        self.activations.append((name, seq_input))\n",
        "        self.layer_idx += 1\n",
        "\n",
        "        # Bidirectional LSTM network\n",
        "        name = \"l{}_bi_lstm\".format(self.layer_idx)\n",
        "        hidden_size = 512   # will output 1024 (512 forward, 512 backward)\n",
        "        with tf.compat.v1.variable_scope(name) as scope:\n",
        "\n",
        "            def lstm_cell():\n",
        "                cell = tf.compat.v1.nn.rnn_cell.LSTMCell(hidden_size,\n",
        "                                                use_peepholes=True,\n",
        "                                                state_is_tuple=True,\n",
        "                                                reuse=tf.compat.v1.get_variable_scope().reuse) \n",
        "                if self.use_dropout_sequence:\n",
        "                    keep_prob = 0.5 if self.is_train else 1.0\n",
        "                    cell = tf.compat.v1.nn.rnn_cell.DropoutWrapper(\n",
        "                        cell,\n",
        "                        output_keep_prob=keep_prob\n",
        "                    )\n",
        "\n",
        "                return cell\n",
        "\n",
        "            fw_cell = tf.compat.v1.nn.rnn_cell.MultiRNNCell([lstm_cell() for _ in range(self.n_rnn_layers)], state_is_tuple = True)\n",
        "            bw_cell = tf.compat.v1.nn.rnn_cell.MultiRNNCell([lstm_cell() for _ in range(self.n_rnn_layers)], state_is_tuple = True)\n",
        "\n",
        "            # Initial state of RNN\n",
        "            self.fw_initial_state = fw_cell.zero_state(self.batch_size, tf.float32)\n",
        "            self.bw_initial_state = bw_cell.zero_state(self.batch_size, tf.float32)\n",
        "\n",
        "            # Feedforward to MultiRNNCell\n",
        "            list_rnn_inputs = tf.unstack(seq_input, axis=1)\n",
        "            outputs, fw_state, bw_state, fw_states, bw_states = custom_bidirectional_rnn(\n",
        "                cell_fw=fw_cell,\n",
        "                cell_bw=bw_cell,\n",
        "                inputs=list_rnn_inputs,\n",
        "                initial_state_fw=self.fw_initial_state,\n",
        "                initial_state_bw=self.bw_initial_state\n",
        "            )\n",
        "\n",
        "            if self.return_last:\n",
        "                network = outputs[-1]\n",
        "            else:\n",
        "                network = tf.reshape(tf.concat(axis=1, values=outputs), [-1, hidden_size*2],\n",
        "                                     name=name)\n",
        "            self.activations.append((name, network))\n",
        "            self.layer_idx +=1\n",
        "\n",
        "            self.fw_final_state = fw_state\n",
        "            self.bw_final_state = bw_state\n",
        "\n",
        "            self.fw_states = fw_states\t\t\n",
        "            self.bw_states = bw_states\n",
        "\n",
        "        # Append output\n",
        "        output_conns.append(network)\n",
        "\n",
        "        ######################################################################\n",
        "\n",
        "        # Add\n",
        "        name = \"l{}_add\".format(self.layer_idx)\n",
        "        network = tf.add_n(output_conns, name=name)\n",
        "        self.activations.append((name, network))\n",
        "        self.layer_idx += 1\n",
        "\n",
        "        # Dropout\n",
        "        if self.use_dropout_sequence:\n",
        "            name = \"l{}_dropout\".format(self.layer_idx)\n",
        "            if self.is_train:\n",
        "                network = tf.nn.dropout(network, keep_prob=0.5, name=name)\n",
        "            else:\n",
        "                network = tf.nn.dropout(network, keep_prob=1.0, name=name)\n",
        "            self.activations.append((name, network))\n",
        "        self.layer_idx += 1\n",
        "\n",
        "        return network\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cEmJdRx9oYFt"
      },
      "source": [
        "def _reverse_seq(input_seq, lengths):\n",
        "    \"\"\"Reverse a list of Tensors up to specified lengths.\n",
        "    Args:\n",
        "        input_seq: Sequence of seq_len tensors of dimension (batch_size, n_features)\n",
        "                   or nested tuples of tensors.\n",
        "        lengths:   A `Tensor` of dimension batch_size, containing lengths for each\n",
        "                   sequence in the batch. If \"None\" is specified, simply reverses\n",
        "                   the list.\n",
        "    Returns:\n",
        "        time-reversed sequence\n",
        "    \"\"\"\n",
        "    if lengths is None:\n",
        "        return list(reversed(input_seq))\n",
        "\n",
        "    flat_input_seq = tuple(nest.flatten(input_) for input_ in input_seq)\n",
        "\n",
        "    flat_results = [[] for _ in range(len(input_seq))]\n",
        "    for sequence in zip(*flat_input_seq):\n",
        "        input_shape = tensor_shape.unknown_shape(\n",
        "                ndims=sequence[0].get_shape().ndims)\n",
        "        for input_ in sequence:\n",
        "            input_shape.merge_with(input_.get_shape())\n",
        "            input_.set_shape(input_shape)\n",
        "\n",
        "        # Join into (time, batch_size, depth)\n",
        "        s_joined = array_ops.pack(sequence)\n",
        "\n",
        "        # TODO(schuster, ebrevdo): Remove cast when reverse_sequence takes int32\n",
        "        if lengths is not None:\n",
        "            lengths = math_ops.to_int64(lengths)\n",
        "\n",
        "        # Reverse along dimension 0\n",
        "        s_reversed = array_ops.reverse_sequence(s_joined, lengths, 0, 1)\n",
        "        # Split again into list\n",
        "        result = array_ops.unpack(s_reversed)\n",
        "        for r, flat_result in zip(result, flat_results):\n",
        "            r.set_shape(input_shape)\n",
        "            flat_result.append(r)\n",
        "\n",
        "    results = [nest.pack_sequence_as(structure=input_, flat_sequence=flat_result)\n",
        "               for input_, flat_result in zip(input_seq, flat_results)]\n",
        "    return results"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 734
        },
        "id": "QhSUpDyfeAQY",
        "outputId": "f96c7428-a43e-454f-cdfc-62c80098ae40"
      },
      "source": [
        "n_subjects = 20\n",
        "n_subjects_per_fold = 1\n",
        "data_dir = \"/content/drive/MyDrive/EEG_classification/EEG/data/eeg_fpz_cz\" #predicted data fold\n",
        "model_dir = \"output\"\n",
        "output_dir = \"output\"\n",
        "with tf.Graph().as_default(), tf.compat.v1.Session() as sess:\n",
        "        # Build the network\n",
        "        valid_net = CustomDeepSleepNet(\n",
        "            batch_size=1, \n",
        "            input_dims=EPOCH_SEC_LEN*100, \n",
        "            n_classes=NUM_CLASSES, \n",
        "            seq_length=25,\n",
        "            n_rnn_layers=2,\n",
        "            return_last=False,\n",
        "            is_train=False, \n",
        "            reuse_params=False, \n",
        "            use_dropout_feature=True, \n",
        "            use_dropout_sequence=True\n",
        "        )\n",
        "\n",
        "        # Initialize parameters\n",
        "        valid_net.init_ops()\n",
        "\n",
        "        for subject_idx in range(n_subjects):\n",
        "            fold_idx = 15 #subject_idx // n_subjects_per_fold\n",
        "\n",
        "            checkpoint_path = os.path.join(\n",
        "                model_dir, \n",
        "                \"fold{}\".format(fold_idx), \n",
        "                \"deepsleepnet/\"\n",
        "            )\n",
        "            checkpoint_path = \"/content/drive/MyDrive/EEG_classification/EEG/output/fold15/deepsleepnet\"\n",
        "            print(checkpoint_path)\n",
        "            # Restore the trained model\n",
        "            saver = tf.compat.v1.train.Saver()\n",
        "            saver.restore(sess, tf.train.latest_checkpoint(checkpoint_path))\n",
        "            print(\"Model restored from: {}\\n\".format(tf.train.latest_checkpoint(checkpoint_path)))\n",
        "\n",
        "            # Load testing data 여기 함수 인풋\n",
        "            x, y = SeqDataLoader.load_subject_data(\n",
        "                data_dir=data_dir, \n",
        "                subject_idx=subject_idx\n",
        "            )\n",
        "\n",
        "            # Loop each epoch\n",
        "            print(\"[{}] Predicting ...\\n\".format(datetime.now()))\n",
        "            fw_state = sess.run(valid_net.fw_initial_state)\n",
        "            bw_state = sess.run(valid_net.bw_initial_state)\n",
        "\n",
        "            n_all_data = len(each_x)\n",
        "            extra = n_all_data % valid_net.seq_length\n",
        "            n_data = n_all_data - extra\n",
        "            cell_size = 512\n",
        "            fw_memory_cells = np.zeros((n_data, valid_net.n_rnn_layers, cell_size))\n",
        "            bw_memory_cells = np.zeros((n_data, valid_net.n_rnn_layers, cell_size))\n",
        "            seq_idx = 0\n",
        "\n",
        "            feed_dict = {\n",
        "                network.input_var: x_batch,\n",
        "                network.target_var: y_batch\n",
        "            }\n",
        "\n",
        "            for i, (c, h) in enumerate(valid_net.fw_initial_state):\n",
        "                feed_dict[c] = fw_state[i].c\n",
        "                feed_dict[h] = fw_state[i].h\n",
        "\n",
        "            for i, (c, h) in enumerate(valid_net.bw_initial_state):\n",
        "                feed_dict[c] = bw_state[i].c\n",
        "                feed_dict[h] = bw_state[i].h\n",
        "\n",
        "            _, loss_value, y_pred, fw_state, bw_state = sess.run(\n",
        "                [tf.no_op(), valid_net.loss_op, valid_net.pred_op, valid_net.fw_final_state, valid_net.bw_final_state],\n",
        "                feed_dict=feed_dict)\n",
        "            \n",
        "           ''' # Evaluate the model on the subject data\n",
        "            y_true_, y_pred_, loss, duration = \\\n",
        "                custom_run_epoch(\n",
        "                    sess=sess, network=valid_net,\n",
        "                    inputs=x, targets=y,\n",
        "                    train_op=tf.no_op(),\n",
        "                    is_train=False,\n",
        "                    output_dir=output_dir,\n",
        "                    subject_idx=subject_idx\n",
        "                )'''\n",
        "              return y_pred\n",
        "          \n",
        "          \n",
        "          \n",
        "          '''  n_examples = len(y_true_)\n",
        "            cm_ = confusion_matrix(y_true_, y_pred_)\n",
        "            acc_ = np.mean(y_true_ == y_pred_)\n",
        "            mf1_ = f1_score(y_true_, y_pred_, average=\"macro\")\n",
        "\n",
        "            # Report performance\n",
        "            print_performance(\n",
        "                sess, valid_net.name,\n",
        "                n_examples, duration, loss, \n",
        "                cm_, acc_, mf1_\n",
        "            )\n",
        "\n",
        "            y_true.extend(y_true_)\n",
        "            y_pred.extend(y_pred_)\n",
        "        \n",
        "# Overall performance\n",
        "print(\"[{}] Overall prediction performance\\n\".format(datetime.now()))\n",
        "y_true = np.asarray(y_true)\n",
        "y_pred = np.asarray(y_pred)\n",
        "n_examples = len(y_true)\n",
        "cm = confusion_matrix(y_true, y_pred)\n",
        "acc = np.mean(y_true == y_pred)\n",
        "mf1 = f1_score(y_true, y_pred, average=\"macro\")\n",
        "print((\n",
        "    \"n={}, acc={:.3f}, f1={:.3f}\".format(\n",
        "        n_examples, acc, mf1\n",
        "    )\n",
        "))\n",
        "print(cm)'''\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /content/drive/MyDrive/EEG_classification/EEG/deepsleep/model.py:91: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "WARNING:tensorflow:From <ipython-input-7-f10fc9611f49>:73: LSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This class is equivalent as tf.keras.layers.LSTMCell, and will be replaced by that in Tensorflow 2.0.\n",
            "WARNING:tensorflow:From <ipython-input-7-f10fc9611f49>:83: MultiRNNCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This class is equivalent as tf.keras.layers.StackedRNNCells, and will be replaced by that in Tensorflow 2.0.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/rnn_cell_impl.py:958: Layer.add_variable (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.add_weight` method instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/rnn_cell_impl.py:962: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "WARNING:tensorflow:\n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n",
            "/content/drive/MyDrive/EEG_classification/EEG/output/fold15/deepsleepnet\n",
            "INFO:tensorflow:Restoring parameters from /content/drive/MyDrive/EEG_classification/EEG/output/fold15/deepsleepnet/model_fold15.ckpt-200\n",
            "Model restored from: /content/drive/MyDrive/EEG_classification/EEG/output/fold15/deepsleepnet/model_fold15.ckpt-200\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-30da15c25dc1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m             \u001b[0;31m# Load testing data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m             x, y = SeqDataLoader.load_subject_data(\n\u001b[0m\u001b[1;32m     41\u001b[0m                 \u001b[0mdata_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata_dir\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m                 \u001b[0msubject_idx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msubject_idx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'SeqDataLoader' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0mw97jY8kqAP"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}